{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhza5NVMlkRg",
        "outputId": "402b482f-0365-43fa-f4e3-7bb28d6d86ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from icrawler) (4.13.5)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from icrawler) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from icrawler) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from icrawler) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2025.10.5)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w87FxKllftY",
        "outputId": "d13f12cf-58ce-4e3a-dd9d-28f35af8ab77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/forgetabhi/top-1000-anime-and-manga-characters-dataset?dataset_version_number=1&file_name=top_anime_characters_cleaned.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195k/195k [00:00<00:00, 2.09MB/s]\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import ast\n",
        "import os\n",
        "import re\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "import time\n",
        "\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BASE_ROOT = 'anime_dataset'  # Root for train/test split\n",
        "TRAIN_ROOT = os.path.join(BASE_ROOT, 'train')\n",
        "TEST_ROOT = os.path.join(BASE_ROOT, 'test')\n",
        "os.makedirs(TRAIN_ROOT, exist_ok=True)\n",
        "os.makedirs(TEST_ROOT, exist_ok=True)\n",
        "\n",
        "\n",
        "df = kagglehub.dataset_load(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"forgetabhi/top-1000-anime-and-manga-characters-dataset\",\n",
        "    \"top_anime_characters_cleaned.csv\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_first_anime(anime_col):\n",
        "    if isinstance(anime_col, str):\n",
        "        anime_list = ast.literal_eval(anime_col)\n",
        "    else:\n",
        "        anime_list = anime_col\n",
        "    return anime_list[0] if anime_list else None\n",
        "\n",
        "df['main_anime'] = df['anime_manga_titles'].apply(get_first_anime)"
      ],
      "metadata": {
        "id": "i17EB3xRl7KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_anime_name(anime_name):\n",
        "    # Split at :, -, (, take first part\n",
        "    anime_clean = re.split(':', anime_name)[0].strip()\n",
        "    anime_clean = re.sub(r'[^\\w\\s]', '', anime_clean)  # remove punctuation\n",
        "    return anime_clean\n"
      ],
      "metadata": {
        "id": "_AufHURKsgrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_split_by_anime(anime_name, character_name, max_images=10):\n",
        "    anime_clean = clean_anime_name(anime_name)\n",
        "    char_clean = re.sub(r',', '', str(character_name)).strip().replace(' ', '_')\n",
        "\n",
        "    temp_folder = f\"/tmp/{anime_clean}_{char_clean}\"\n",
        "    os.makedirs(temp_folder, exist_ok=True)\n",
        "\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": temp_folder})\n",
        "    try:\n",
        "        crawler.crawl(keyword=f\"{character_name}\", max_num=max_images)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {character_name}: {e}\")\n",
        "        shutil.rmtree(temp_folder, ignore_errors=True)\n",
        "        return\n",
        "\n",
        "    images = [f for f in os.listdir(temp_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    if len(images) < 3:\n",
        "        print(f\"Skipping {character_name} ({anime_name}): only {len(images)} images\")\n",
        "        shutil.rmtree(temp_folder, ignore_errors=True)\n",
        "        return\n",
        "\n",
        "    # Create folders for this anime\n",
        "    train_folder = os.path.join(TRAIN_ROOT, anime_clean)\n",
        "    test_folder = os.path.join(TEST_ROOT, anime_clean)\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    # Calculate current counts to offset filenames\n",
        "    existing_train = len(os.listdir(train_folder))\n",
        "    existing_test = len(os.listdir(test_folder))\n",
        "\n",
        "    # Move all images randomly: 80% train, 20% test\n",
        "    images.sort()\n",
        "    split_index = int(len(images) * 0.8)\n",
        "    train_images, test_images = images[:split_index], images[split_index:]\n",
        "\n",
        "    # Save new train images with unique names\n",
        "    for i, img in enumerate(train_images, start=existing_train + 1):\n",
        "        ext = os.path.splitext(img)[1]\n",
        "        dest_name = f\"{anime_clean}_{char_clean}_train_{i:04d}{ext}\"\n",
        "        shutil.move(os.path.join(temp_folder, img), os.path.join(train_folder, dest_name))\n",
        "\n",
        "    # Save new test images with unique names\n",
        "    for i, img in enumerate(test_images, start=existing_test + 1):\n",
        "        ext = os.path.splitext(img)[1]\n",
        "        dest_name = f\"{anime_clean}_{char_clean}_test_{i:04d}{ext}\"\n",
        "        shutil.move(os.path.join(temp_folder, img), os.path.join(test_folder, dest_name))\n",
        "\n",
        "    shutil.rmtree(temp_folder, ignore_errors=True)\n",
        "    print(f\"{anime_name}: {len(train_images)} new train, {len(test_images)} new test images added\")\n",
        "\n",
        "# Example loop\n",
        "downloaded = set()\n",
        "for idx, row in enumerate(df.itertuples(index=False), start=1):\n",
        "    anime = getattr(row, 'main_anime', None)\n",
        "    char = getattr(row, 'name_english', None)\n",
        "\n",
        "    if not anime or not char or (anime, char) in downloaded:\n",
        "        continue\n",
        "\n",
        "    print(f\"[{idx}/{len(df)}] {anime} - {char}\")\n",
        "    download_and_split_by_anime(anime, char)\n",
        "    downloaded.add((anime, char))\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "JcxYyy9Tl7uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c91ff2c-f680-433c-8d17-4b37f634dcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/1050] Code Geass: Hangyaku no Lelouch - Lamperouge, Lelouch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 403, file https://rare-gallery.com/uploads/posts/188348-lelouch-lamperouge-1920x1200.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code Geass: Hangyaku no Lelouch: 8 new train, 2 new test images added\n",
            "[2/1050] Shingeki no Kyojin: Kuinaki Sentaku - Levi\n",
            "Shingeki no Kyojin: Kuinaki Sentaku: 8 new train, 2 new test images added\n",
            "[3/1050] One Piece - Monkey D., Luffy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 404, file https://vignette.wikia.nocookie.net/heros/images/e/e4/Monkey_D_Luffy_Infobox.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"/content/anime_dataset\", 'zip', \"/content/anime_dataset\")\n"
      ],
      "metadata": {
        "id": "_FzJ_KOt4Zb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/anime_dataset.zip\")"
      ],
      "metadata": {
        "id": "wDKp2tyi4bIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}